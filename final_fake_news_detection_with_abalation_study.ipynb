{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WXWSV6UriSLe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eS1Svp8lb8I",
        "outputId": "827b8dd2-faf5-40b7-abe1-d3b497a989ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "afM9a9lLiSLk"
      },
      "outputs": [],
      "source": [
        "# ------------------ 1. Load Files ------------------\n",
        "stance_file = \"/content/drive/MyDrive/keepup project methodology code/aggregated_stance_counts.csv\"\n",
        "claims_file = \"/content/drive/MyDrive/keepup project methodology code/entailment_predictions_results.csv\"\n",
        "post_file = \"/content/drive/MyDrive/keepup project methodology code/post_combined_features.csv\"\n",
        "user_file = \"/content/drive/MyDrive/keepup project methodology code/user_combined_features.csv\"\n",
        "excel_file = \"/content/drive/MyDrive/keepup project methodology code/Final dataset.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7gulODCRiSLl"
      },
      "outputs": [],
      "source": [
        "# Read CSVs\n",
        "stance_df = pd.read_csv(stance_file)\n",
        "entail_df = pd.read_csv(claims_file)\n",
        "postf_df = pd.read_csv(post_file)\n",
        "userf_df = pd.read_csv(user_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2CvBXZGyiSLm"
      },
      "outputs": [],
      "source": [
        "# Read Excel sheets\n",
        "post_df = pd.read_excel(excel_file, sheet_name=\"post features\")\n",
        "user_df = pd.read_excel(excel_file, sheet_name=\"user features\")\n",
        "comments_df = pd.read_excel(excel_file, sheet_name=\"comments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BWNQd7aGiSLn"
      },
      "outputs": [],
      "source": [
        "# ------------------ 2. Merge Feature DataFrames ------------------\n",
        "data = post_df.merge(stance_df, left_on=\"post-id\", right_on=\"post_id\", how=\"left\")\n",
        "data = data.merge(entail_df, left_on=\"Event-id\", right_on=\"claim-id\", how=\"left\")\n",
        "data = data.merge(user_df, on=\"post-id\", how=\"left\")\n",
        "data = data.merge(postf_df, left_on=\"event_id\", right_on=\"post_id\", how=\"left\")\n",
        "data = data.merge(userf_df, on=\"post-id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K3612k-NiSLn"
      },
      "outputs": [],
      "source": [
        "# Safely combine comments by converting each to a string\n",
        "combined_comments = comments_df.groupby(\"post-id\")[\"commenttext\"].apply(\n",
        "    lambda x: \" \".join(str(i) for i in x)\n",
        ").reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1vkx39kOiSLo"
      },
      "outputs": [],
      "source": [
        "# Ensure commenttext exists and handle potential issues\n",
        "comments_df['commenttext'] = comments_df['commenttext'].fillna('').astype(str)\n",
        "\n",
        "# Group and safely combine all comments as strings\n",
        "combined_comments = (\n",
        "    comments_df.groupby(\"post-id\")[\"commenttext\"]\n",
        "    .apply(lambda x: \" \".join(x.astype(str).tolist()))\n",
        "    .reset_index()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8wvKFu4wiSLq"
      },
      "outputs": [],
      "source": [
        "# ------------------ 3. Aggregate Comments per Post ------------------\n",
        "# Group and combine all comments for each post_id\n",
        "combined_comments = comments_df.groupby(\"post-id\")[\"commenttext\"].apply(lambda x: \" \".join(x)).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gAgx8Vh6iSLr"
      },
      "outputs": [],
      "source": [
        "# ------------------ 4. Merge Title & Comments ------------------\n",
        "# Merge titles using post-id\n",
        "data = data.merge(post_df, on=\"post-id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nTmXmFJKiSLr"
      },
      "outputs": [],
      "source": [
        "# Merge combined comments using post-id\n",
        "data = data.merge(combined_comments, left_on=\"post-id\", right_on=\"post-id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tjbkz7h9iSLr"
      },
      "outputs": [],
      "source": [
        "# ------------------ 5. Combine Title + Comments into One Field ------------------\n",
        "data[\"combined_text\"] = data[\"title\"].fillna('') + \" \" + data[\"commenttext\"].fillna('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "8444b0c331084c66a7058d3eea638357",
            "cfec842d6957428d907843b1d85c6e9c",
            "419a19e72a6c42ed8b9cdd9ee93dea43",
            "703ebda1456d4bfa8b3dd59674f8968a",
            "b49503ff32784666a4f0ce395d1bc3d5",
            "b79858fc42ff4e4b886447fc78229a0b",
            "6a5e1738c3c04d1fae6356347ade7234",
            "2d5aecf4402b4300a6f0f1542efcd52c",
            "2da4106747354ccd92dc7991fb68a70d",
            "95677617a75d410b8f2b35ad66253e12",
            "578f540a481a4383bcbd318be42703c7",
            "02741fff559f4b7db278dfa473a6fb01",
            "e95a98ef3fc34e2cb79244015ae4ddca",
            "e65794ef82194c7db36287b72289bfc9",
            "bf789e92a51e4a8eb3208c341dbfa47e",
            "1f152424551548598c1411fe1d1d6642",
            "4a66d6eb4e0a4c3ab8c9fba9da06e751",
            "dbf4aefb556d4fe7ac79c9cf6a981582",
            "83a71e4f383d45048b76b0de6ba83e9f",
            "82a1ec097f7f4a8d9b387bb4e81c122e",
            "e7066548291e446bb83d6714145f010e",
            "90569c0fdbf44b6ba09ae12b829c12f4",
            "f455312df8524678ab1a178b8413d4b1",
            "03eb55a59a04452791ca053fb37bc6ea",
            "75797a2bc51c4d8db09afee1a01213c9",
            "507cf988bf00489aa29b484f3212b7b3",
            "3f804685cdd942bb8ab0a17559089fa7",
            "acd70237463e4127a1670055a93831b6",
            "c78b285ba4d1491fa780ad5217e135d1",
            "2be9a7da71c148c3971c7257d51160b6",
            "db9f74bc5aaf414ea0e403a4e2c6875a",
            "60693f16df7c437d8c82b19db293880a",
            "b95718dcf31f418b98efeccef0a3859f",
            "a59770156ab94277ab1bfc6a9698192a",
            "d1b1bc8fc8bf4415b54bd3cce6fdbbe5",
            "9e3fcc0287b14e94bd91f1e822f3420c",
            "b506d460cbac4f58a69639357ae6013a",
            "8c6bc7ed5c634f269378ab81d86923be",
            "c202539aeca74c3d8b837391a7e77486",
            "87a8cea40b634cc281abe98e0e61b724",
            "48efb209e65a4173ae24e33f2930ffd2",
            "b7fe41fc3f7d431e8d532d6ce668079f",
            "1b9910081cc84285b63796a46042bcfe",
            "7c13d0770f34461db8333de73f22f1e3",
            "9cba3fc1482f4b7bbb8daa594bb33909",
            "ba323fea139c454384071fe73b3503fd",
            "dcc8035bd79c466eafbc4f36e76a5dd2",
            "079cce012f0f46b28e57017ae203eaef",
            "6ba8f4ecc8c04a58aa614b5535b3cdb6",
            "e697fa1eefe64191b81edeab77835e26",
            "b5c6da11fdfd49d3ac3d1f4e0e772703",
            "0f6c4de0a4954bae8bbd7a0f9607dfea",
            "2b490e2e0b0d4d61bb94720fdda53b9e",
            "bfb8a7188c554c4981d729f791178f84",
            "1d58bd77194d4b27903a91e2639e8dc5"
          ]
        },
        "id": "VB1SQPPkiSLs",
        "outputId": "aabbd1d1-bc7f-4712-dbf4-26daaf3669f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8444b0c331084c66a7058d3eea638357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02741fff559f4b7db278dfa473a6fb01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f455312df8524678ab1a178b8413d4b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a59770156ab94277ab1bfc6a9698192a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cba3fc1482f4b7bbb8daa594bb33909"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1024/1024 [09:04<00:00,  1.88it/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load XLM-Roberta\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "model = AutoModel.from_pretrained('xlm-roberta-base')\n",
        "model.eval()\n",
        "\n",
        "# Generate mean pooled embeddings for combined_text\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "# Apply embedding extraction (use tqdm for progress bar)\n",
        "tqdm.pandas()\n",
        "data[\"embedding\"] = data[\"combined_text\"].progress_apply(get_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "eCTy5OaHiSLs"
      },
      "outputs": [],
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['likescount_x', 'commentscount_x', 'followers_y', 'followings_y',\n",
        "                  'is user verified(0 verified, 1 unverified)_y', 'join_days_ago',\n",
        "                  'stance_agree', 'stance_disagree', 'stance_query', 'stance_comment',\n",
        "                   'positive_prob','title_length', 'title_sentiment', 'clickbait_flag','post-title_x', 'commenttext']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "HrV7LPYEiSLt"
      },
      "outputs": [],
      "source": [
        "X_text = np.stack(data['embedding'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON5wgqDniSLt",
        "outputId": "e6f8cc04-ef05-41cf-894a-f8388b411449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "likescount_x unique values (sample): [2.5000e+04 3.0000e+01 2.4000e+01 6.2000e+01 6.2584e+04]\n",
            "commentscount_x unique values (sample): [1704.    4.    6.    3.  711.]\n",
            "followers_y unique values (sample): [1.80e+04 2.40e+04 4.80e+03 1.01e+03 3.50e+06]\n",
            "followings_y unique values (sample): [    0.  2659. 65300.   463.   868.]\n",
            "is user verified(0 verified, 1 unverified)_y unique values (sample): [1 0]\n",
            "join_days_ago unique values (sample): [   0. 4903.  734. 3929. 6517.]\n",
            "stance_agree unique values (sample): [159.   0.   5.  15.   7.]\n",
            "stance_disagree unique values (sample): [507.   0.   3.   2.   1.]\n",
            "stance_query unique values (sample): [75.  1.  0.  4.  8.]\n",
            "stance_comment unique values (sample): [963.   3.   1. 675.   6.]\n",
            "positive_prob unique values (sample): [0.]\n",
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n",
            "post-title_x unique values (sample): [0.]\n",
            "commenttext unique values (sample): [0.00000000e+00 3.00621111e+09]\n"
          ]
        }
      ],
      "source": [
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "TkiRhrkuiSLt"
      },
      "outputs": [],
      "source": [
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "zt9U9OAsiSLu"
      },
      "outputs": [],
      "source": [
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "Qy4brfmfiSLu"
      },
      "outputs": [],
      "source": [
        "data[numerical_cols] = data[numerical_cols].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "IZWg_CjtiSLu"
      },
      "outputs": [],
      "source": [
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "7Ixvud8miSLu"
      },
      "outputs": [],
      "source": [
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "xX_6hA_xiSLu"
      },
      "outputs": [],
      "source": [
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8FpfVHdJkrpf"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split 80:20"
      ],
      "metadata": {
        "id": "8sXiMwMBucBk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "9bJy1O-SiSLv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAxzGOh_iSLx"
      },
      "outputs": [],
      "source": [
        "#CNN+Bi_GRU ENSEMBLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "AJH5xktpy3ct"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "ZTG40jHUyen3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLUznCDApQEi",
        "outputId": "15b03219-7884-4a0e-c0e4-c05ab3d242e9"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 10.3691 | Train Acc: 52.63% | Test Acc: 53.66%\n",
            "Epoch 02 | Loss: 9.4639 | Train Acc: 57.26% | Test Acc: 47.80%\n",
            "Epoch 03 | Loss: 9.2285 | Train Acc: 59.58% | Test Acc: 53.17%\n",
            "Epoch 04 | Loss: 8.8458 | Train Acc: 61.05% | Test Acc: 71.71%\n",
            "Epoch 05 | Loss: 8.2297 | Train Acc: 64.22% | Test Acc: 73.17%\n",
            "Epoch 06 | Loss: 8.6283 | Train Acc: 63.25% | Test Acc: 70.24%\n",
            "Epoch 07 | Loss: 8.1842 | Train Acc: 67.16% | Test Acc: 60.00%\n",
            "Epoch 08 | Loss: 7.7244 | Train Acc: 70.45% | Test Acc: 61.95%\n",
            "Epoch 09 | Loss: 7.8816 | Train Acc: 67.89% | Test Acc: 66.34%\n",
            "Epoch 10 | Loss: 7.4687 | Train Acc: 68.01% | Test Acc: 68.78%\n",
            "Early stopping at epoch 10. Best Test Acc: 73.17%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 73.17%\n",
            "Confusion Matrix:\n",
            "[[60 35]\n",
            " [20 90]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7500    0.6316    0.6857        95\n",
            "           1     0.7200    0.8182    0.7660       110\n",
            "\n",
            "    accuracy                         0.7317       205\n",
            "   macro avg     0.7350    0.7249    0.7258       205\n",
            "weighted avg     0.7339    0.7317    0.7288       205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# split dataset 90:10"
      ],
      "metadata": {
        "id": "ZtmeElVzuUrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n"
      ],
      "metadata": {
        "id": "n37y2mn4qswB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n"
      ],
      "metadata": {
        "id": "wfO5Ze2luJlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "IbeIs-j5uO82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFYAOA8T0pnI",
        "outputId": "e987312c-d883-458b-9aa6-92c00bfddfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Loss: 23.6397 | Train Acc: 52.77% | Test Acc: 50.49%\n",
            "Epoch 02 | Loss: 21.3151 | Train Acc: 58.74% | Test Acc: 66.02%\n",
            "Epoch 03 | Loss: 20.5819 | Train Acc: 58.85% | Test Acc: 70.87%\n",
            "Epoch 04 | Loss: 19.4197 | Train Acc: 62.43% | Test Acc: 71.84%\n",
            "Epoch 05 | Loss: 19.1942 | Train Acc: 62.21% | Test Acc: 62.14%\n",
            "Epoch 06 | Loss: 18.7187 | Train Acc: 64.50% | Test Acc: 78.64%\n",
            "Epoch 07 | Loss: 18.2749 | Train Acc: 66.12% | Test Acc: 57.28%\n",
            "Epoch 08 | Loss: 18.4906 | Train Acc: 64.06% | Test Acc: 72.82%\n",
            "Epoch 09 | Loss: 17.4652 | Train Acc: 67.43% | Test Acc: 73.79%\n",
            "Epoch 10 | Loss: 17.3900 | Train Acc: 68.73% | Test Acc: 69.90%\n",
            "Epoch 11 | Loss: 17.5114 | Train Acc: 68.08% | Test Acc: 73.79%\n",
            "Early stopping at epoch 11. Best Test Acc: 78.64%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 78.64%\n",
            "Confusion Matrix:\n",
            "[[33 15]\n",
            " [ 7 48]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8250    0.6875    0.7500        48\n",
            "           1     0.7619    0.8727    0.8136        55\n",
            "\n",
            "    accuracy                         0.7864       103\n",
            "   macro avg     0.7935    0.7801    0.7818       103\n",
            "weighted avg     0.7913    0.7864    0.7839       103\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abalation study"
      ],
      "metadata": {
        "id": "qSFrkD0VljOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "without entailment positive prob"
      ],
      "metadata": {
        "id": "EotAayhUlr3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pN5no09viSLz"
      },
      "outputs": [],
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['likescount_x', 'commentscount_x', 'followers_y', 'followings_y',\n",
        "                  'is user verified(0 verified, 1 unverified)_y', 'join_days_ago',\n",
        "                  'stance_agree', 'stance_disagree', 'stance_query', 'stance_comment', 'title_length', 'title_sentiment', 'clickbait_flag']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "o2ewc_sCiSMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92df1d76-072a-42e8-b03b-368e79d5f28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "likescount_x unique values (sample): [2.5000e+04 3.0000e+01 2.4000e+01 6.2000e+01 6.2584e+04]\n",
            "commentscount_x unique values (sample): [1704.    4.    6.    3.  711.]\n",
            "followers_y unique values (sample): [1.80e+04 2.40e+04 4.80e+03 1.01e+03 3.50e+06]\n",
            "followings_y unique values (sample): [    0.  2659. 65300.   463.   868.]\n",
            "is user verified(0 verified, 1 unverified)_y unique values (sample): [1 0]\n",
            "join_days_ago unique values (sample): [   0. 4903.  734. 3929. 6517.]\n",
            "stance_agree unique values (sample): [159.   0.   5.  15.   7.]\n",
            "stance_disagree unique values (sample): [507.   0.   3.   2.   1.]\n",
            "stance_query unique values (sample): [75.  1.  0.  4.  8.]\n",
            "stance_comment unique values (sample): [963.   3.   1. 675.   6.]\n",
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n"
          ]
        }
      ],
      "source": [
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "t8uKgESgmC1t"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj_8ihRemGAq",
        "outputId": "b195f2e5-d965-435f-ee7d-f8c16476b1e2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 22.2307 | Train Acc: 56.03% | Test Acc: 56.31%\n",
            "Epoch 02 | Loss: 20.9494 | Train Acc: 60.48% | Test Acc: 68.93%\n",
            "Epoch 03 | Loss: 19.1360 | Train Acc: 62.54% | Test Acc: 76.70%\n",
            "Epoch 04 | Loss: 19.6680 | Train Acc: 62.32% | Test Acc: 72.82%\n",
            "Epoch 05 | Loss: 19.2028 | Train Acc: 63.95% | Test Acc: 64.08%\n",
            "Epoch 06 | Loss: 18.1265 | Train Acc: 65.47% | Test Acc: 71.84%\n",
            "Epoch 07 | Loss: 17.6475 | Train Acc: 67.32% | Test Acc: 69.90%\n",
            "Epoch 08 | Loss: 17.7632 | Train Acc: 67.21% | Test Acc: 71.84%\n",
            "Early stopping at epoch 8. Best Test Acc: 76.70%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 76.70%\n",
            "Confusion Matrix:\n",
            "[[35 13]\n",
            " [11 44]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7609    0.7292    0.7447        48\n",
            "           1     0.7719    0.8000    0.7857        55\n",
            "\n",
            "    accuracy                         0.7670       103\n",
            "   macro avg     0.7664    0.7646    0.7652       103\n",
            "weighted avg     0.7668    0.7670    0.7666       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "without stance aggregation and enatilment"
      ],
      "metadata": {
        "id": "JsDLR_1Jmrdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['likescount_x', 'commentscount_x', 'followers_y', 'followings_y',\n",
        "                  'is user verified(0 verified, 1 unverified)_y', 'join_days_ago',\n",
        "                  'title_length', 'title_sentiment', 'clickbait_flag']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q0-3DRhmuRX",
        "outputId": "2a4436ef-2dbb-495b-e009-6ff7b80cba13"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "likescount_x unique values (sample): [2.5000e+04 3.0000e+01 2.4000e+01 6.2000e+01 6.2584e+04]\n",
            "commentscount_x unique values (sample): [1704.    4.    6.    3.  711.]\n",
            "followers_y unique values (sample): [1.80e+04 2.40e+04 4.80e+03 1.01e+03 3.50e+06]\n",
            "followings_y unique values (sample): [    0.  2659. 65300.   463.   868.]\n",
            "is user verified(0 verified, 1 unverified)_y unique values (sample): [1 0]\n",
            "join_days_ago unique values (sample): [   0. 4903.  734. 3929. 6517.]\n",
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n",
            "Epoch 01 | Loss: 22.5690 | Train Acc: 53.53% | Test Acc: 71.84%\n",
            "Epoch 02 | Loss: 21.4803 | Train Acc: 57.98% | Test Acc: 69.90%\n",
            "Epoch 03 | Loss: 19.5780 | Train Acc: 62.11% | Test Acc: 70.87%\n",
            "Epoch 04 | Loss: 18.7392 | Train Acc: 62.43% | Test Acc: 75.73%\n",
            "Epoch 05 | Loss: 18.8642 | Train Acc: 65.36% | Test Acc: 71.84%\n",
            "Epoch 06 | Loss: 18.0994 | Train Acc: 63.84% | Test Acc: 67.96%\n",
            "Epoch 07 | Loss: 18.1943 | Train Acc: 66.12% | Test Acc: 67.96%\n",
            "Epoch 08 | Loss: 17.2225 | Train Acc: 67.21% | Test Acc: 66.02%\n",
            "Epoch 09 | Loss: 16.5084 | Train Acc: 69.16% | Test Acc: 69.90%\n",
            "Early stopping at epoch 9. Best Test Acc: 75.73%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 75.73%\n",
            "Confusion Matrix:\n",
            "[[31 17]\n",
            " [ 8 47]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7949    0.6458    0.7126        48\n",
            "           1     0.7344    0.8545    0.7899        55\n",
            "\n",
            "    accuracy                         0.7573       103\n",
            "   macro avg     0.7646    0.7502    0.7513       103\n",
            "weighted avg     0.7626    0.7573    0.7539       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "only title+title features"
      ],
      "metadata": {
        "id": "lQMyNRK1nOVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['title_length', 'title_sentiment', 'clickbait_flag']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usxj-lmRnRiE",
        "outputId": "2a838b31-539a-41c9-eb69-17fc17183be9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n",
            "Epoch 01 | Loss: 21.9246 | Train Acc: 56.03% | Test Acc: 63.11%\n",
            "Epoch 02 | Loss: 20.1801 | Train Acc: 61.02% | Test Acc: 62.14%\n",
            "Epoch 03 | Loss: 20.0255 | Train Acc: 60.48% | Test Acc: 71.84%\n",
            "Epoch 04 | Loss: 19.4021 | Train Acc: 61.13% | Test Acc: 65.05%\n",
            "Epoch 05 | Loss: 18.6753 | Train Acc: 64.93% | Test Acc: 70.87%\n",
            "Epoch 06 | Loss: 18.4781 | Train Acc: 65.91% | Test Acc: 71.84%\n",
            "Epoch 07 | Loss: 17.9541 | Train Acc: 66.88% | Test Acc: 60.19%\n",
            "Epoch 08 | Loss: 18.2616 | Train Acc: 67.43% | Test Acc: 65.05%\n",
            "Early stopping at epoch 8. Best Test Acc: 71.84%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 71.84%\n",
            "Confusion Matrix:\n",
            "[[26 22]\n",
            " [ 7 48]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7879    0.5417    0.6420        48\n",
            "           1     0.6857    0.8727    0.7680        55\n",
            "\n",
            "    accuracy                         0.7184       103\n",
            "   macro avg     0.7368    0.7072    0.7050       103\n",
            "weighted avg     0.7333    0.7184    0.7093       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "only title"
      ],
      "metadata": {
        "id": "zGnm1Z9Cndty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['post-title_x']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKc0Btp8ndDw",
        "outputId": "a74fad03-34da-4d08-f933-a988ee8ea9be"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "post-title_x unique values (sample): ['وفاقی اردو یونیورسٹی کی جانب سے ارشد ندیم کود ہزار روپے کا انعام..❤️'\n",
            " \"وفاقی اردو یونیورسٹی کی جانب سے ارشد ندیم کو دو ہزار روپے کا انعام ❤️\\n.\\n.\\n.\\n.\\n.\\n.\\nToday's Best Photo ❤❤❤❤❤❤\\nFollow me \\n❤❤❤❤❤❤❤❤\\n#photography \\n#photooftheday \\n#photographychallenge \\n#PhotoEditingChallenge\\n#BestPhotographyChallenge\\n#photochallenge \\n#moodchallengemoodchallenge \\n#moodchallengechallenge1kToday\\n#RaisZada #RaisZadaUbaid #Ubaid ❤️\"\n",
            " 'وفاقی اردو یونیورسٹی نے ارشد ندیم کو 2000 روپے کی خطیر رقم کا چیک دیا  ، اللہ کا شکر ہے ارشد ندیم بحفاظت گھر تک پہنچ گئے ۔'\n",
            " 'unseen footage of arshad nadeem and maryam nawaz… hug each other'\n",
            " 'ارشد ندیم کی بیوی نے پہلی بار ٹی وی پر آکر انکشاف کر دیاجب میدان میں ناکامی ہوتی تو کیا کرتی تھی؟ \\n#sunonewshd #ArshadNadeem #arshadnadeemgoldmedal #arshadnadeemfamily']\n",
            "Epoch 01 | Loss: 22.3301 | Train Acc: 55.05% | Test Acc: 66.99%\n",
            "Epoch 02 | Loss: 20.7613 | Train Acc: 59.07% | Test Acc: 68.93%\n",
            "Epoch 03 | Loss: 20.4152 | Train Acc: 58.31% | Test Acc: 60.19%\n",
            "Epoch 04 | Loss: 19.7067 | Train Acc: 62.32% | Test Acc: 56.31%\n",
            "Epoch 05 | Loss: 19.3418 | Train Acc: 61.56% | Test Acc: 66.99%\n",
            "Epoch 06 | Loss: 18.3514 | Train Acc: 64.82% | Test Acc: 69.90%\n",
            "Epoch 07 | Loss: 17.7965 | Train Acc: 67.43% | Test Acc: 72.82%\n",
            "Epoch 08 | Loss: 18.0925 | Train Acc: 66.34% | Test Acc: 63.11%\n",
            "Epoch 09 | Loss: 17.4453 | Train Acc: 68.73% | Test Acc: 62.14%\n",
            "Epoch 10 | Loss: 17.2351 | Train Acc: 68.30% | Test Acc: 73.79%\n",
            "Epoch 11 | Loss: 16.5668 | Train Acc: 68.51% | Test Acc: 70.87%\n",
            "Epoch 12 | Loss: 17.3455 | Train Acc: 68.08% | Test Acc: 69.90%\n",
            "Epoch 13 | Loss: 16.6001 | Train Acc: 68.19% | Test Acc: 71.84%\n",
            "Epoch 14 | Loss: 15.6651 | Train Acc: 71.55% | Test Acc: 71.84%\n",
            "Epoch 15 | Loss: 15.6683 | Train Acc: 71.88% | Test Acc: 71.84%\n",
            "Early stopping at epoch 15. Best Test Acc: 73.79%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 73.79%\n",
            "Confusion Matrix:\n",
            "[[39  9]\n",
            " [18 37]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6842    0.8125    0.7429        48\n",
            "           1     0.8043    0.6727    0.7327        55\n",
            "\n",
            "    accuracy                         0.7379       103\n",
            "   macro avg     0.7443    0.7426    0.7378       103\n",
            "weighted avg     0.7484    0.7379    0.7374       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "title + Comment"
      ],
      "metadata": {
        "id": "XkTDbLblnqjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['post-title_x', 'commenttext']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdad4f8onnza",
        "outputId": "f1f6a471-39e1-4ea7-e1c9-12583622aa1e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "post-title_x unique values (sample): [0.]\n",
            "commenttext unique values (sample): [0.00000000e+00 3.00621111e+09]\n",
            "Epoch 01 | Loss: 21.3352 | Train Acc: 56.68% | Test Acc: 70.87%\n",
            "Epoch 02 | Loss: 20.6317 | Train Acc: 57.98% | Test Acc: 59.22%\n",
            "Epoch 03 | Loss: 19.7693 | Train Acc: 62.21% | Test Acc: 73.79%\n",
            "Epoch 04 | Loss: 19.3519 | Train Acc: 60.37% | Test Acc: 74.76%\n",
            "Epoch 05 | Loss: 19.0190 | Train Acc: 63.19% | Test Acc: 75.73%\n",
            "Epoch 06 | Loss: 18.3563 | Train Acc: 63.41% | Test Acc: 75.73%\n",
            "Epoch 07 | Loss: 18.3879 | Train Acc: 65.91% | Test Acc: 75.73%\n",
            "Epoch 08 | Loss: 18.1121 | Train Acc: 65.80% | Test Acc: 66.99%\n",
            "Epoch 09 | Loss: 17.5734 | Train Acc: 66.88% | Test Acc: 74.76%\n",
            "Epoch 10 | Loss: 17.5097 | Train Acc: 69.60% | Test Acc: 60.19%\n",
            "Early stopping at epoch 10. Best Test Acc: 75.73%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 75.73%\n",
            "Confusion Matrix:\n",
            "[[32 16]\n",
            " [ 9 46]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7805    0.6667    0.7191        48\n",
            "           1     0.7419    0.8364    0.7863        55\n",
            "\n",
            "    accuracy                         0.7573       103\n",
            "   macro avg     0.7612    0.7515    0.7527       103\n",
            "weighted avg     0.7599    0.7573    0.7550       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "content +social engagemnents"
      ],
      "metadata": {
        "id": "yvc-Ryk8oB5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['likescount_x', 'commentscount_x','commenttext',\n",
        "                  'title_length', 'title_sentiment', 'clickbait_flag']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrUObJejn9bh",
        "outputId": "1c4ce5fa-5d0d-41d0-8160-53cca05705b2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "likescount_x unique values (sample): [2.5000e+04 3.0000e+01 2.4000e+01 6.2000e+01 6.2584e+04]\n",
            "commentscount_x unique values (sample): [1704.    4.    6.    3.  711.]\n",
            "commenttext unique values (sample): [0.00000000e+00 3.00621111e+09]\n",
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n",
            "Epoch 01 | Loss: 21.7954 | Train Acc: 55.05% | Test Acc: 62.14%\n",
            "Epoch 02 | Loss: 20.5424 | Train Acc: 58.63% | Test Acc: 73.79%\n",
            "Epoch 03 | Loss: 20.3627 | Train Acc: 60.59% | Test Acc: 73.79%\n",
            "Epoch 04 | Loss: 19.0645 | Train Acc: 63.63% | Test Acc: 73.79%\n",
            "Epoch 05 | Loss: 18.8779 | Train Acc: 63.84% | Test Acc: 60.19%\n",
            "Epoch 06 | Loss: 18.4735 | Train Acc: 63.84% | Test Acc: 71.84%\n",
            "Epoch 07 | Loss: 18.2953 | Train Acc: 65.58% | Test Acc: 68.93%\n",
            "Early stopping at epoch 7. Best Test Acc: 73.79%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 73.79%\n",
            "Confusion Matrix:\n",
            "[[27 21]\n",
            " [ 6 49]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8182    0.5625    0.6667        48\n",
            "           1     0.7000    0.8909    0.7840        55\n",
            "\n",
            "    accuracy                         0.7379       103\n",
            "   macro avg     0.7591    0.7267    0.7253       103\n",
            "weighted avg     0.7551    0.7379    0.7293       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#content+user profiling"
      ],
      "metadata": {
        "id": "zpfecNdtoaLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to array\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "\n",
        "# Select numeric features (update with real column names)\n",
        "numerical_cols = ['followers_y', 'followings_y',\n",
        "                  'is user verified(0 verified, 1 unverified)_y', 'join_days_ago',\n",
        "                  'title_length', 'title_sentiment', 'clickbait_flag']\n",
        "\n",
        "X_numeric = data[numerical_cols].fillna(0).values  # Handle NaNs if any\n",
        "\n",
        "# Combine text embeddings and numeric features\n",
        "X = np.hstack([X_text, X_numeric])\n",
        "\n",
        "# Target variable\n",
        "y = data['post-label_x'].values  # Make sure this column exists\n",
        "X_text = np.stack(data['embedding'].values)\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col} unique values (sample):\", data[col].unique()[:5])\n",
        "def parse_shorthand(value):\n",
        "    try:\n",
        "        value = str(value).strip().lower()\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1_000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1_000_000\n",
        "        else:\n",
        "            return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "for col in numerical_cols:\n",
        "    # Only apply to object (string-like) columns\n",
        "    if data[col].dtype == 'object':\n",
        "        data[col] = data[col].apply(parse_shorthand)\n",
        "data[numerical_cols] = data[numerical_cols].fillna(0)\n",
        "other_feature_columns = [col for col in numerical_cols if col != 'post-title_x']\n",
        "other_features = data[other_feature_columns].values.astype(np.float32)\n",
        "X_numeric = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "X = np.hstack([X_text, X_numeric]).astype(np.float32)\n",
        "\n",
        "# Clean embeddings\n",
        "embedding_features = np.array([np.array(e, dtype=np.float32) for e in data['embedding'].values])\n",
        "numeric_features = data[numerical_cols].fillna(0).astype(np.float32).values\n",
        "labels = data['post-label_x'].values\n",
        "\n",
        "# Train/test split\n",
        "X_embed_train, X_embed_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    embedding_features, numeric_features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to tensors\n",
        "X_embed_train_tensor = torch.tensor(X_embed_train, dtype=torch.float32).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "X_embed_test_tensor = torch.tensor(X_embed_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_num_train_tensor = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_test_tensor = torch.tensor(X_num_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(X_embed_train_tensor, X_num_train_tensor, y_train_tensor)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_embed_test_tensor, X_num_test_tensor, y_test_tensor)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class EnsembleDataset(Dataset):\n",
        "    def __init__(self, texts, numeric_features, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.numeric_features = numeric_features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        numeric = torch.tensor(self.numeric_features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze(0)           # (seq_len)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0) # (seq_len)\n",
        "\n",
        "        return input_ids, attention_mask, numeric, label\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, gru_output):\n",
        "        # gru_output: (batch, seq_len, hidden_dim)\n",
        "        attn_weights = F.softmax(self.attn(gru_output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * gru_output, dim=1)   # (batch, hidden_dim)\n",
        "        return context\n",
        "\n",
        "# CNN Feature Extractor\n",
        "class CNNExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(CNNExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)                    # (batch, embed_dim, seq_len)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)             # (batch, 32)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# BiGRU with Attention Feature Extractor\n",
        "class BiGRUExtractor(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size=64):\n",
        "        super(BiGRUExtractor, self).__init__()\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(hidden_size * 2)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)                      # (batch, seq_len, hidden*2)\n",
        "        attn_out = self.attention(out)            # (batch, hidden*2)\n",
        "        attn_out = self.bn(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "        return attn_out\n",
        "\n",
        "# Full Ensemble Model\n",
        "class EnsembleSmallData(nn.Module):\n",
        "    def __init__(self, embed_dim, num_features, num_classes=2):\n",
        "        super(EnsembleSmallData, self).__init__()\n",
        "        self.cnn_branch = CNNExtractor(embed_dim)\n",
        "        self.gru_branch = BiGRUExtractor(embed_dim, hidden_size=64)\n",
        "        self.fc_numeric = nn.Linear(num_features, 32)\n",
        "        self.bn_numeric = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.classifier = nn.Linear(32 + 128 + 32, num_classes)  # CNN(32) + GRU(128) + numeric(32)\n",
        "\n",
        "    def forward(self, embed_x, numeric_x):\n",
        "        cnn_feat = self.cnn_branch(embed_x)                           # (batch, 32)\n",
        "        gru_feat = self.gru_branch(embed_x)                           # (batch, 128)\n",
        "        num_feat = F.relu(self.bn_numeric(self.fc_numeric(numeric_x)))# (batch, 32)\n",
        "        num_feat = self.dropout(num_feat)\n",
        "\n",
        "        combined = torch.cat([cnn_feat, gru_feat, num_feat], dim=1)   # (batch, 192)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        out = self.classifier(combined)                               # (batch, num_classes)\n",
        "        return out\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import copy\n",
        "\n",
        "model = EnsembleSmallData(\n",
        "    embed_dim=X_embed_train.shape[1],\n",
        "    num_features=X_num_train.shape[1],\n",
        "    num_classes=2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping\n",
        "best_acc = 0\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_model_state = None\n",
        "best_preds = []\n",
        "best_labels = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for xb_embed, xb_num, yb in train_dl:\n",
        "        xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb_embed, xb_num)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "        train_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb_embed, xb_num, yb in test_dl:\n",
        "            xb_embed, xb_num, yb = xb_embed.to(device), xb_num.to(device), yb.to(device)\n",
        "            preds = model(xb_embed, xb_num)\n",
        "            test_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            test_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save best model and predictions\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_preds = test_preds.copy()\n",
        "        best_labels = test_labels.copy()\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}. Best Test Acc: {best_acc*100:.2f}%\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Final evaluation on best model\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "print(f\"Best Test Accuracy: {best_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(best_labels, best_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(best_labels, best_preds, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mneWwDhUodXp",
        "outputId": "210cd1ea-6b34-4217-bcd7-200ba19bf054"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "followers_y unique values (sample): [1.80e+04 2.40e+04 4.80e+03 1.01e+03 3.50e+06]\n",
            "followings_y unique values (sample): [    0.  2659. 65300.   463.   868.]\n",
            "is user verified(0 verified, 1 unverified)_y unique values (sample): [1 0]\n",
            "join_days_ago unique values (sample): [   0. 4903.  734. 3929. 6517.]\n",
            "title_length unique values (sample): [0.]\n",
            "title_sentiment unique values (sample): [0.]\n",
            "clickbait_flag unique values (sample): [0.]\n",
            "Epoch 01 | Loss: 23.3475 | Train Acc: 52.12% | Test Acc: 69.90%\n",
            "Epoch 02 | Loss: 21.1183 | Train Acc: 56.24% | Test Acc: 72.82%\n",
            "Epoch 03 | Loss: 20.2781 | Train Acc: 59.83% | Test Acc: 70.87%\n",
            "Epoch 04 | Loss: 19.5542 | Train Acc: 59.28% | Test Acc: 71.84%\n",
            "Epoch 05 | Loss: 18.8246 | Train Acc: 62.65% | Test Acc: 76.70%\n",
            "Epoch 06 | Loss: 18.5631 | Train Acc: 63.52% | Test Acc: 76.70%\n",
            "Epoch 07 | Loss: 18.0071 | Train Acc: 66.88% | Test Acc: 70.87%\n",
            "Epoch 08 | Loss: 17.3447 | Train Acc: 68.95% | Test Acc: 74.76%\n",
            "Epoch 09 | Loss: 17.3867 | Train Acc: 67.54% | Test Acc: 75.73%\n",
            "Epoch 10 | Loss: 17.0814 | Train Acc: 70.14% | Test Acc: 73.79%\n",
            "Early stopping at epoch 10. Best Test Acc: 76.70%\n",
            "\n",
            "--- Final Evaluation on Best Model ---\n",
            "Best Test Accuracy: 76.70%\n",
            "Confusion Matrix:\n",
            "[[32 16]\n",
            " [ 8 47]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8000    0.6667    0.7273        48\n",
            "           1     0.7460    0.8545    0.7966        55\n",
            "\n",
            "    accuracy                         0.7670       103\n",
            "   macro avg     0.7730    0.7606    0.7619       103\n",
            "weighted avg     0.7712    0.7670    0.7643       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPRt7DQTsgv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8444b0c331084c66a7058d3eea638357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfec842d6957428d907843b1d85c6e9c",
              "IPY_MODEL_419a19e72a6c42ed8b9cdd9ee93dea43",
              "IPY_MODEL_703ebda1456d4bfa8b3dd59674f8968a"
            ],
            "layout": "IPY_MODEL_b49503ff32784666a4f0ce395d1bc3d5"
          }
        },
        "cfec842d6957428d907843b1d85c6e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79858fc42ff4e4b886447fc78229a0b",
            "placeholder": "​",
            "style": "IPY_MODEL_6a5e1738c3c04d1fae6356347ade7234",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "419a19e72a6c42ed8b9cdd9ee93dea43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5aecf4402b4300a6f0f1542efcd52c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2da4106747354ccd92dc7991fb68a70d",
            "value": 25
          }
        },
        "703ebda1456d4bfa8b3dd59674f8968a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95677617a75d410b8f2b35ad66253e12",
            "placeholder": "​",
            "style": "IPY_MODEL_578f540a481a4383bcbd318be42703c7",
            "value": " 25.0/25.0 [00:00&lt;00:00, 581B/s]"
          }
        },
        "b49503ff32784666a4f0ce395d1bc3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79858fc42ff4e4b886447fc78229a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5e1738c3c04d1fae6356347ade7234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d5aecf4402b4300a6f0f1542efcd52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da4106747354ccd92dc7991fb68a70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95677617a75d410b8f2b35ad66253e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578f540a481a4383bcbd318be42703c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02741fff559f4b7db278dfa473a6fb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e95a98ef3fc34e2cb79244015ae4ddca",
              "IPY_MODEL_e65794ef82194c7db36287b72289bfc9",
              "IPY_MODEL_bf789e92a51e4a8eb3208c341dbfa47e"
            ],
            "layout": "IPY_MODEL_1f152424551548598c1411fe1d1d6642"
          }
        },
        "e95a98ef3fc34e2cb79244015ae4ddca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a66d6eb4e0a4c3ab8c9fba9da06e751",
            "placeholder": "​",
            "style": "IPY_MODEL_dbf4aefb556d4fe7ac79c9cf6a981582",
            "value": "config.json: 100%"
          }
        },
        "e65794ef82194c7db36287b72289bfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a71e4f383d45048b76b0de6ba83e9f",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82a1ec097f7f4a8d9b387bb4e81c122e",
            "value": 615
          }
        },
        "bf789e92a51e4a8eb3208c341dbfa47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7066548291e446bb83d6714145f010e",
            "placeholder": "​",
            "style": "IPY_MODEL_90569c0fdbf44b6ba09ae12b829c12f4",
            "value": " 615/615 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "1f152424551548598c1411fe1d1d6642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a66d6eb4e0a4c3ab8c9fba9da06e751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf4aefb556d4fe7ac79c9cf6a981582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a71e4f383d45048b76b0de6ba83e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a1ec097f7f4a8d9b387bb4e81c122e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7066548291e446bb83d6714145f010e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90569c0fdbf44b6ba09ae12b829c12f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f455312df8524678ab1a178b8413d4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03eb55a59a04452791ca053fb37bc6ea",
              "IPY_MODEL_75797a2bc51c4d8db09afee1a01213c9",
              "IPY_MODEL_507cf988bf00489aa29b484f3212b7b3"
            ],
            "layout": "IPY_MODEL_3f804685cdd942bb8ab0a17559089fa7"
          }
        },
        "03eb55a59a04452791ca053fb37bc6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd70237463e4127a1670055a93831b6",
            "placeholder": "​",
            "style": "IPY_MODEL_c78b285ba4d1491fa780ad5217e135d1",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "75797a2bc51c4d8db09afee1a01213c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be9a7da71c148c3971c7257d51160b6",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db9f74bc5aaf414ea0e403a4e2c6875a",
            "value": 5069051
          }
        },
        "507cf988bf00489aa29b484f3212b7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60693f16df7c437d8c82b19db293880a",
            "placeholder": "​",
            "style": "IPY_MODEL_b95718dcf31f418b98efeccef0a3859f",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "3f804685cdd942bb8ab0a17559089fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd70237463e4127a1670055a93831b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78b285ba4d1491fa780ad5217e135d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be9a7da71c148c3971c7257d51160b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9f74bc5aaf414ea0e403a4e2c6875a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60693f16df7c437d8c82b19db293880a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95718dcf31f418b98efeccef0a3859f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59770156ab94277ab1bfc6a9698192a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1b1bc8fc8bf4415b54bd3cce6fdbbe5",
              "IPY_MODEL_9e3fcc0287b14e94bd91f1e822f3420c",
              "IPY_MODEL_b506d460cbac4f58a69639357ae6013a"
            ],
            "layout": "IPY_MODEL_8c6bc7ed5c634f269378ab81d86923be"
          }
        },
        "d1b1bc8fc8bf4415b54bd3cce6fdbbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c202539aeca74c3d8b837391a7e77486",
            "placeholder": "​",
            "style": "IPY_MODEL_87a8cea40b634cc281abe98e0e61b724",
            "value": "tokenizer.json: 100%"
          }
        },
        "9e3fcc0287b14e94bd91f1e822f3420c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48efb209e65a4173ae24e33f2930ffd2",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7fe41fc3f7d431e8d532d6ce668079f",
            "value": 9096718
          }
        },
        "b506d460cbac4f58a69639357ae6013a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9910081cc84285b63796a46042bcfe",
            "placeholder": "​",
            "style": "IPY_MODEL_7c13d0770f34461db8333de73f22f1e3",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "8c6bc7ed5c634f269378ab81d86923be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c202539aeca74c3d8b837391a7e77486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a8cea40b634cc281abe98e0e61b724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48efb209e65a4173ae24e33f2930ffd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7fe41fc3f7d431e8d532d6ce668079f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b9910081cc84285b63796a46042bcfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c13d0770f34461db8333de73f22f1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cba3fc1482f4b7bbb8daa594bb33909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba323fea139c454384071fe73b3503fd",
              "IPY_MODEL_dcc8035bd79c466eafbc4f36e76a5dd2",
              "IPY_MODEL_079cce012f0f46b28e57017ae203eaef"
            ],
            "layout": "IPY_MODEL_6ba8f4ecc8c04a58aa614b5535b3cdb6"
          }
        },
        "ba323fea139c454384071fe73b3503fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e697fa1eefe64191b81edeab77835e26",
            "placeholder": "​",
            "style": "IPY_MODEL_b5c6da11fdfd49d3ac3d1f4e0e772703",
            "value": "model.safetensors: 100%"
          }
        },
        "dcc8035bd79c466eafbc4f36e76a5dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6c4de0a4954bae8bbd7a0f9607dfea",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b490e2e0b0d4d61bb94720fdda53b9e",
            "value": 1115567652
          }
        },
        "079cce012f0f46b28e57017ae203eaef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb8a7188c554c4981d729f791178f84",
            "placeholder": "​",
            "style": "IPY_MODEL_1d58bd77194d4b27903a91e2639e8dc5",
            "value": " 1.12G/1.12G [00:27&lt;00:00, 60.8MB/s]"
          }
        },
        "6ba8f4ecc8c04a58aa614b5535b3cdb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e697fa1eefe64191b81edeab77835e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c6da11fdfd49d3ac3d1f4e0e772703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f6c4de0a4954bae8bbd7a0f9607dfea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b490e2e0b0d4d61bb94720fdda53b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfb8a7188c554c4981d729f791178f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d58bd77194d4b27903a91e2639e8dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}